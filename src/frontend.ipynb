{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import eel\n",
    "import shutil\n",
    "import tkinter\n",
    "import utils.trees as trees\n",
    "import utils.parsing as parsing\n",
    "import utils.ranking as ranking\n",
    "import utils.scraping as scraping\n",
    "import utils.constants as constants\n",
    "import utils.text_processing as text_processing\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, dim = text_processing.load_embeddings(constants.STARSPACE_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application terminated successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "2022-05-11T16:29:26Z\n"
     ]
    }
   ],
   "source": [
    "def close_callback(route, websockets):\n",
    "    if not websockets:\n",
    "        print(\"Application terminated successfully!\")\n",
    "        return\n",
    "\n",
    "eel.init(\"frontend\", allowed_extensions=[\".js\", \".html\"])\n",
    "\n",
    "@eel.expose\n",
    "def get_paper_results(search_query):\n",
    "    return scraping.scrape_semantic_scholar(search_query, 9)\n",
    "\n",
    "@eel.expose\n",
    "def get_paper_details(paper_id):\n",
    "    return scraping.scrape_semantic_scholar_by_id(paper_id)[paper_id]\n",
    "\n",
    "@eel.expose\n",
    "def get_similar_papers_subjects(paper, subjects, keywords, top_n):\n",
    "    return ranking.rank_candidates_per_subject(\n",
    "        paper, \n",
    "        top_n, \n",
    "        embeddings, \n",
    "        dim, \n",
    "        subjects, \n",
    "        include_embeddings=False,\n",
    "        stringify=True, \n",
    "        keywords=keywords\n",
    "    )\n",
    "\n",
    "@eel.expose\n",
    "def get_similar_papers_neighborhood(paper_id, paper, keywords, top_n):\n",
    "    return ranking.rank_citation_neighborhood(\n",
    "        paper_id,\n",
    "        paper,\n",
    "        top_n,\n",
    "        embeddings,\n",
    "        dim, \n",
    "        include_embeddings=False,\n",
    "        stringify=True,\n",
    "        keywords=keywords\n",
    "    )\n",
    "\n",
    "@eel.expose\n",
    "def get_similar_papers_all(paper, subjects, keywords, top_n):\n",
    "    return ranking.rank_candidates_adjusted(\n",
    "        paper,\n",
    "        top_n,\n",
    "        embeddings,\n",
    "        dim,\n",
    "        subjects,\n",
    "        include_embeddings = False,\n",
    "        stringify=True,\n",
    "        keywords=keywords\n",
    "    )\n",
    "\n",
    "@eel.expose\n",
    "def get_reference_tree(paper_id, paper):\n",
    "\n",
    "    papers = {paper_id: paper}\n",
    "\n",
    "    trees.build_semantic_scholar_reference_tree(paper_id, papers, depth = 2)\n",
    "    fig = trees.visualize_reference_tree_plotly(papers)\n",
    "    figJSON = fig.to_plotly_json()\n",
    "\n",
    "    return figJSON\n",
    "\n",
    "@eel.expose\n",
    "def get_paper_subject(abstract): \n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(constants.SUBJECT_LABELING_MODEL_SINGLE)\n",
    "    subject = model.predict([abstract])[0]\n",
    "    return subject\n",
    "\n",
    "@eel.expose\n",
    "def get_pdf_information():\n",
    "\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    file_name = tkinter.filedialog.askopenfilename()\n",
    "    root.destroy()\n",
    "\n",
    "    if not os.path.exists(constants.USER_UPLOAD_DIR):\n",
    "        os.makedirs(constants.USER_UPLOAD_DIR)\n",
    "\n",
    "    if os.path.exists(constants.USER_UPLOAD):\n",
    "        os.remove(constants.USER_UPLOAD)\n",
    "\n",
    "    if os.path.exists(constants.USER_UPLOAD_CERM):\n",
    "        os.remove(constants.USER_UPLOAD_CERM)\n",
    "\n",
    "    papers = {}\n",
    "\n",
    "    shutil.copyfile(file_name, constants.USER_UPLOAD)\n",
    "    parsing.parse_pdfs_to_xml(pdfs_dir=str(constants.USER_UPLOAD_DIR))\n",
    "    parsing.integrate_xml(papers, pdfs_dir=constants.USER_UPLOAD_DIR)\n",
    "\n",
    "    return papers['user_input']\n",
    "\n",
    "eel.start(\"index.html\", size=(1200,800), close_callback=close_callback, mode = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9970e3cda3553e643a72630d158f5eb20b938c22781a4c3ade3fdbb209395361"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
