{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.constants as constants\n",
    "import utils.text_processing as text_processing\n",
    "import utils.ranking as ranking\n",
    "import utils.multi_ranking as multi_ranking\n",
    "import utils.text_processing as text_processing\n",
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, dim = text_processing.load_embeddings(constants.STARSPACE_EMBEDDINGS)\n",
    "paper = {\"abstract\": \"We propose to use Rademacher complexity, originally developed in computational learning theory, as a measure of human learning capacity. Rademacher complex- ity measures a learner’s ability to fit random labels, and can be used to bound the learner’s true error based on the observed training sample error. We first re- view the definition of Rademacher complexity and its generalization bound. We then describe a “learning the noise” procedure to experimentally measure human Rademacher complexities. The results from empirical studies showed that: (i) human Rademacher complexity can be successfully measured, (ii) the complex- ity depends on the domain and training sample size in intuitive ways, (iii) hu- man learning respects the generalization bounds, (iv) the bounds can be useful in predicting the danger of overfitting in human learning. Finally, we discuss the potential applications of human Rademacher complexity in cognitive science.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ranked = multi_ranking.rank_candidates_per_subject(paper, 10, embeddings, dim, constants.SUBJECTS, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ranked = ranking.rank_candidates_per_subject(paper, 10, embeddings, dim, constants.SUBJECTS, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = ranking.build_citation_neighborhood(\"395de0bd3837fdf4b4b5e5f04835bcc69c279481\")\n",
    "data = pd.DataFrame.from_dict(citations, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, dim = text_processing.load_embeddings(constants.STARSPACE_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = ranking.rank_citation_neighborhood(\"395de0bd3837fdf4b4b5e5f04835bcc69c279481\", {\"abstract\": \"We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.\"}, 100, embeddings, dim, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = ranking.rank_candidates_adjusted(paper, 1000, embeddings, dim, constants.SUBJECTS)\n",
    "data_ranked = pd.DataFrame(ranked, columns=[\"ID\", \"FILE\", \"DISTANCE\", \"SUBJECT\", \"TITLE\", \"ABSTRACT\", \"EMBEDDING\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_reducer2D = umap.UMAP(n_components=2)\n",
    "\n",
    "data_ranked[\"SIMILARITY\"] = 1 - MinMaxScaler().fit_transform(data_ranked[\"DISTANCE\"].values.reshape((-1, 1)))\n",
    "data_ranked[\"SIMILARITY\"] = data_ranked[\"SIMILARITY\"].clip(lower=0)\n",
    "\n",
    "initial_embeddings = np.stack(data_ranked[\"EMBEDDING\"])\n",
    "mapped_embeddings = umap_reducer2D.fit_transform(initial_embeddings)\n",
    "\n",
    "data_ranked[\"X\"] = mapped_embeddings[:, 0]\n",
    "data_ranked[\"Y\"] = mapped_embeddings[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data_ranked, x=\"X\", y=\"Y\", color = \"SUBJECT\", height=800, hover_name=\"TITLE\", size=\"SIMILARITY\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9970e3cda3553e643a72630d158f5eb20b938c22781a4c3ade3fdbb209395361"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
